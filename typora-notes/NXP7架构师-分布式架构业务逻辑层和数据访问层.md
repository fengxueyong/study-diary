# 分布式架构业务逻辑层和数据访问

## 分布式架构业务逻辑层技术分析

### 架构分层目的

![image-20220612150906178](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220612150906178.png)



架构分层，每一层所做的事就更加单一，每一层就更容易代码规范。



### 业务逻辑层核心功能

![image-20220612153303605](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220612153303605.png)



其中1,2有一些通用的工具可以使用，特别是java

3.4，就完全是业务逻辑。每个人的风格也不一样，需要架构师进行把控。

### 业务逻辑层设计原则

![image-20220612154118074](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220612154118074.png)

#### 谋定而后动

![image-20220612154450765](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220612154450765.png)

**信息架构**

> 站在用户的角度看待我的小程序，我的app具有怎样的功能点

比如微信，一直以来就只有四大块：微信、通讯录、发现、我。



##### 短视频业务系统重构实践

【在下一次课中讲解，未细看】



#### 单向依赖

![image-20220612160500079](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220612160500079.png)



这里要注意不能循环，这个也是大家经常有时候干的事情。

这里涉及到很多回调的情况，底层在一定的时候会回调通知上层，这个时候就可以使用观察者模式，注册监听器就行了。

#### 接口语义明确

<img src="NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220612161014100.png" alt="image-20220612161014100" style="zoom:50%;" />

实际上就是用接近于自己业务系统的语义来定义接口的名字，能够自解释。

实际上就是避免，insert，update这样的接口，接口名称要具有业务含义。



#### 参数最小化

<img src="NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220612161203558.png" alt="image-20220612161203558" style="zoom:67%;" />



<img src="NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220612161554399.png" alt="image-20220612161554399" style="zoom:67%;" />



#### 异常反馈感知

![image-20220612162312832](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220612162312832.png)

如果有异常了，按照上面的流程，需要经历很长的时间。原因是没有及时的发现。

如果有监控系统，那么就能很快定位到问题并及时修改



### 业务编排方案

![image-20220612162703949](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220612162703949.png)

同步和异步是指RPC

单向调用指的是MQ。

![image-20220612162941197](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220612162941197.png)



## 分布式架构数据访问层技术分析

### 数据访问层

![image-20220612163504672](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220612163504672.png)

![image-20220612163551362](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220612163551362.png)



为什么要加一层数据访问层？  一是解耦，二是隔离（隔离复杂性），将复杂性控制在局部，不影响业务逻辑。





## 分布式架构数据访问层核心功能剖析

<img src="NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220612163945799.png" alt="image-20220612163945799" style="zoom:80%;" />

注意，缓存和数据库连接池是和CRUD逻辑在一个服务里面的



如果涉及到事务，尽量由业务进行规避或解决。







## 分布式架构数据访问层分库分表解决方案

### 常用扩展方式

#### 封库分表

![image-20220612205134065](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220612205134065.png)

分库很简单，就是垂直分库，一般按照业务来划分，原来在一个实例，可以分到不同的实例里面

分表，比如水平分表，比如表有一亿条数据，分成128张表，一开始可以放在一个库里，然后慢慢分成多个库，最多128个库，如果128个还不够，那就要做扩容，比如扩展到1024个表。



#### 读写分离

![image-20220612205735525](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220612205735525.png)



### 数据库扩展后带来的问题

#### 1.请求路由的问题

##### 分表规则

比如分段：0~10000是一个段， 10001到20000是一个段。比如hash，用uid%128取余数来分表

<img src="NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613090011972.png" alt="image-20220613090011972" style="zoom:67%;" />

ShardingSphere有三款产品：sharding-jdbc， sharding-proxy，还有一个？



![image-20220613091115923](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613091115923.png)

sharding-jdbc支持任意数据库，但是sharding-porxy目前只支持有限的几种（包括mysql），语言的支持则相反。

![image-20220613092631731](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613092631731.png)



一般我们可能使用混合的模式，也就是应用层使用sharding-jdbc，而对于DBA或线下的数据库操作，则采用sharding-proxy模式。









#### 2. 数据库事务的问题

![image-20220613100204300](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613100204300.png)



![image-20220613101057938](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613101057938.png)







![image-20220613101038736](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613101038736.png)



这里面有个问题，逆向补偿的时候如何确定记录，shardingsphere要求不能自增主键。



![image-20220613101328843](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613101328843.png)



Seata



![image-20220613112615510](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613112615510.png)



Seata的三种角色：

RM：相当于每个本地数据库

TM：事务管理器

TC：单独运行的事务协调器



![image-20220613112723027](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613112723027.png)

tm是控制中心，控制整个全局事务

tc类似于管家，协调的角色

rm是具体做事的人，接收指令并完成事务的开启和提交



![image-20220613112942797](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613112942797.png)



![image-20220613114629528](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613114629528.png)

![image-20220613120431996](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613120431996.png)



这里注意下一下，一阶段（rm向tc注册分支的时候）实际上就执行了SQL，只是没有提交或回滚。只有当tm告诉tc可以回滚或提交的时候rm才会回滚或提交。

上图可以看到，一阶段rm在执行sql之前都有生成镜像，比如sql为update name='x' where id=3;

此时数据库里面name=y，id=3，那么前景想就是name=y，id=3，后镜像就是name=x，id=3

![image-20220613125835530](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613125835530.png)



![image-20220613204802754](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613204802754.png)



上面第一个图是一个执行阶段的步骤，可以看到DB里面有个事务表，前景想后镜像的相关数据都要保存在这张表中。

上面第二个图更加清晰：

1. 解析SQL

2. 生成前景想

3. 执行sQL（业务表）

4. 生成后镜像

5. 插入UNDO日志（有专门的表）

6. 向TC注册分支事务

7. 提交（针对3的提交）

8. 向TC报告状态（本地事务执行的状态）

   

![image-20220613130128334](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613130128334.png)



![image-20220613205134285](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613205134285.png)



TC告诉rm提交的时候，RM需要删除undolog，并提交本地事务。因为这个时候实际上业务的sQL已经提交，因此这个时候仅仅是根据分支事务找到对应的undo日志，删除，同时提交（undo log的提交，不是业务sql的提交），因为这个无关业务，因此可以让TC去发起操作。



有几个问题总结一下：

1. 各个RM的本地事务实际上在第一阶段就提交了，也就是RM在注册分支事件之后就提交，完成后才会向TC报告状态
2. Seata实际上是基于XA的二阶段理论，TC相当于分担了TM的部分职责，比如TM提交的时候，TC代替TM向RM发送指令回滚或提交。将元TM的职责分为两个来处理一个好处是事务的状态可以集中在TC上管理和监控。而且TM在执行了事务主流程之后就可以干别的事了。而让TC负责后续的回滚和提交操作。。
3. TC部署的时候需要考虑高可用，因为是有状态的，它保存了所有的事务的状态。



下面我们来看看seata事务的回滚，

如果seata在第一阶段全局事务执行发生了错误或异常，那么TM就会通知TC去回滚这个事务，TC就会依次同时RM去回滚事务。这个是AT模式的第二阶段，而且是回滚阶段。

![image-20220613205811223](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613205811223.png)

1. 找到undo log
2. 检查后镜像
3. 执行回滚操作（业务表）
4. 删除回滚日志
5. 提交
6. 报告状态

如果是回滚的情况，TC是同步驱动回滚，如果回滚再失败，TC可以异步再回滚。





![image-20220613202627856](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613202627856.png)



![image-20220613202905929](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613202905929.png)

上述的图进一步说明，

对于在回滚的时候如果有其他事务修改了数据如何办？这里面涉及到本地锁和全局锁，Seata方案是有这两种锁的，这两种锁就是协调跨事务对DB更新的问题。







下面举个例子：



![image-20220613203142776](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613203142776.png)



undo log保存：

![image-20220613203227861](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613203227861.png)





Seata除了AT模式，还有TCC模式，Saga模式，等，但是最常用，推荐的还是AT模式。







![image-20220613210101051](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613210101051.png)



![image-20220613210125130](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613210125130.png)

上图为一个使用的大概介绍，Seata业务是无浸入的，顶多是本地要建立一个表作为undo log。







## 分布式架构数据访问层缓存访问设计

1. 引入缓存的目的

<img src="NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613221012991.png" alt="image-20220613221012991" style="zoom:50%;" />

注意，缓存一定是为了抗读的。

2. 关键问题

<img src="NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613221054073.png" alt="image-20220613221054073" style="zoom: 50%;" />

所以缓存的使用场景一定要满足，读多写少并且缓存和数据库不要求强一致性。 如果要达到强一致性，对不起，你不要用缓存，有缓存，那模型一定要是最终一致性模型，只不过这个最终一致性的窗口期长短的问题。比如可以是10s，5s，1s等。

3. 总体思路

   <img src="NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613221651980.png" alt="image-20220613221651980" style="zoom: 67%;" />

**插入数据**

只需要把数据插入到MySQL，无需对REdis进行任何操作。为什么插入不做Redis的更新，

1. 是减少复杂性，因为本身redis就是为了查询，在写入数据的时候简单处理，不更新redis，而在查询的时候发现数据不一致再进行更新。

2. 而是带来数据的不一致性性，考虑如下场景：

   <img src="NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613222716126.png" alt="image-20220613222716126" style="zoom:50%;" />

   进程1，向db写入3的时候，这时候还没写redis，但是在写redis之前进程2向db写入4，并同时写入4到redis；然后进程1写入redis3， 这个时候db的x=4， redis依然=3，出现不一致。这种在高并发下出现的不一致是所有写数据都会出现的问题。因此写入一般不写redis。

   也就是ABBA问题，因为不是原子操作。故导致数据的不一致。

**查询数据**

<img src="NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613222022683.png" alt="image-20220613222022683" style="zoom:67%;" />



**删除数据**

<img src="NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613223600381.png" alt="image-20220613223600381" style="zoom:67%;" />

为什么不是先闪redis，再删mysql

如果先删redis，redis删了之后可能会有另外的请求把mysql的数据带过来。为什么发生这种情况，因为数据要以mysql为根本，必须先删mysql，才能让redis不至于数据不一致。、

这里面还有问题，如果删Mysql失败了，没关系，两个数据还是一致的。

如果删了mysql成功，但是删除Redis失败了，怎么办？



**更新数据**

<img src="NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613224131019.png" alt="image-20220613224131019" style="zoom:50%;" />



更新失败，OK，数据还是一致的

如果更新成功，则删除redis数据，注意为什么是删，而不是更新，这个和插入是一致的。不管是删还是插入，都是对数据的变更，对数据的变更，就会导致数据的不一致（操作时序等不一致导致）

<img src="NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613224438091.png" alt="image-20220613224438091" style="zoom:67%;" />

还是ABA的问题，进程2在1的两个操作之间插入了，最好导致了db和redis的值不一致

好问题来了，redis删除失败了怎么办？



也就是，删除数据，更新数据的第二部删除redis失败了怎么办，下面看优化方案：

<img src="NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613224723581.png" alt="image-20220613224723581" style="zoom:67%;" />

1. 过期策略

   删除失败就失败了，设置过期时间，总有过期的时候，过期了就会自动删除（相当于删除成功了），这种方式优点：成本低（缓存管理和开发都低），缺点是：一致性的时间完全依赖过期时间。

2. 事务消息

   <img src="NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613225048963.png" alt="image-20220613225048963" style="zoom:67%;" />

   3. binlog

      <img src="NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613225327589.png" alt="image-20220613225327589" style="zoom:67%;" />

      4. 离线任务

      <img src="NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613225355130.png" alt="image-20220613225355130" style="zoom:67%;" />

      5. 分布式锁

      <img src="NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220613225439482.png" alt="image-20220613225439482" style="zoom: 67%;" />







## 分布式架构数据访问层模型设计实践

### 订单库设计

![image-20220614084001565](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220614084001565.png)



如果这个表已经1个亿了，是不是要分表了。

![image-20220614083935920](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220614083935920.png)

卖家和买家是n：m的关系，那么如何分表，如果按照买家分表，那么按照卖家查询的时候需要跨多个表取数据；同样如果按照卖家分表，也会出现这样的情况。

也就是说怎么分表都不合适

这个也就是多对多的关系模型，如何分表才能达到不需要跨表查询

通常的解决方案就是多存一条记录。

![image-20220614084525795](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220614084525795.png)

每插入一条数据，我就多存一条记录，buyer和seller刚好相反，另外再加一个字段表示方向性，如上图所示，比如这里direction可以表示买的关系（buyer向seller买），如果是0表示卖（201卖给101），这样在buyer和seller上做分表就没问题了。

（查询的时候按buyer查，如果是要买的关系，direction就是1，如果要查卖的关系，direction就是0）

![image-20220614084901691](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220614084901691.png)



in_turn就是那个方向字段，1/0两个值

然后用order_id进行分表主键（采用雪花算法）

![image-20220614091144248](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220614091144248.png)

雪花算法，1（符号为），41（毫秒时间戳），8位（官方是10位，1024）机器编号，14位count值（4096）。

时钟回拨问题（闰秒问题），每过几年，地球自转收到大海潮汐等影响可能变慢或变快，那么时钟就要回拨1秒。如下是代码：

![image-20220614091628166](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220614091628166.png)

如果大厂肯定会考虑这个问题。如果是小厂，日活几百万的也要考虑这个问题。



![image-20220614091930142](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220614091930142.png)



如上是shardingSphere的配置

因为我们是通过orderId进行分表，为了让同一个buyerId不会落到不同的表中，那么必须达到根据orderId进行分表和根据buyerId进行分表具有一样的数据分布，那么这个就是基因注入：



![image-20220614092232682](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220614092232682.png)

order_id和buyer_id中间的8位必须一致，这样就达到了目的。这样不管buyerId是多少，通过orderId进行分表后一定落到同一张表中。

如下是具体的代码：

![image-20220614092536184](NXP7架构师-分布式架构业务逻辑层和数据访问层.assets/image-20220614092536184.png)



